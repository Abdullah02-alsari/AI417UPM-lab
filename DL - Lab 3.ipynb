{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a5dac8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2e383e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor(2., requires_grad=True)\n",
      "y: tensor(10., requires_grad=True)\n",
      "w: tensor(3., requires_grad=True)\n",
      "b tensor(5., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create tensor without requires_grad = True\n",
    "x = torch.tensor(2.0,requires_grad=True) # Input tensor\n",
    "y = torch.tensor(10.0,requires_grad=True)\n",
    "b=torch.tensor(5.0,requires_grad=True)\n",
    "w = torch.tensor(3.0, requires_grad=True)\n",
    "# Print the tensors\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"w:\", w)\n",
    "print(\"b\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8e756b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(6., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a function y_hat for the tensors\n",
    "y_hat = w * x # Output / Predictions\n",
    "\n",
    "print(\"y_hat:\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5e4c177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(16., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2dc35532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the gradients for all tensors that have requires_grad=True, by calling the backward function for loss\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bbb3bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : tensor(-24.)\n",
      "w.grad : tensor(-16.)\n"
     ]
    }
   ],
   "source": [
    "# Access and print the gradients with respect to x and w\n",
    "dx = x.grad  # x does not have requires_grad=True, so dx will be None\n",
    "dw = w.grad  # w has requires_grad=True, so dw will contain the gradient\n",
    "\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7813161e-56b9-4cac-95cd-c53359b2ad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.data.zero_()\n",
    "x.grad.data.zero_()\n",
    "b.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "aaaeee72-fbec-4c94-a4bf-a2c45531e11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(11., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_hat = w * x + b\n",
    "print(\"y_hat:\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "decc978f-c912-4ed6-b9d9-5e107a9da8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(1., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b8f1fec0-deff-4599-9385-efa75824628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "61873755-efdb-4cf7-a54f-64ab3507773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : tensor(6.)\n",
      "w.grad : tensor(4.)\n",
      "b.grad =  tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "dx = x.grad  # x does not have requires_grad=True, so dx will be None\n",
    "dw = w.grad  # w has requires_grad=True, so dw will contain the gradient\n",
    "db=b.grad\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)\n",
    "print(\"b.grad = \",db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6364f054-f6c7-4fef-80d8-523f6733efdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.data.zero_()\n",
    "x.grad.data.zero_()\n",
    "b.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0271736b-7065-4144-be0b-cfa5d6c5e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor(2., requires_grad=True)\n",
      "y: tensor(10., requires_grad=True)\n",
      "w: tensor(3., requires_grad=True)\n",
      "b tensor(5., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"w:\", w)\n",
    "print(\"b\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c0393f7a-d6b2-4d5d-8889-66d00c9415bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(12.5000, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a function y_hat for the tensors\n",
    "y_hat = w * x**2+0.5 # Output / Predictions\n",
    "\n",
    "print(\"y_hat:\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fb8b942b-9ad3-42c3-ae07-3523f43925e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(6.2500, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e1e8af4c-7559-4ab9-bdd5-4623955f1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "35ce88cb-1688-4abd-859c-878555ea70f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : tensor(60.)\n",
      "w.grad : tensor(20.)\n",
      "b.grad =  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "dx = x.grad  # x does not have requires_grad=True, so dx will be None\n",
    "dw = w.grad  # w has requires_grad=True, so dw will contain the gradient\n",
    "db=b.grad\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)\n",
    "print(\"b.grad = \",db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "df34550a-8ef3-4447-aa34-64617471a410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.data.zero_()\n",
    "x.grad.data.zero_()\n",
    "b.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3ff815a0-1652-4e40-8a4a-90c864def0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor(2., requires_grad=True)\n",
      "y: tensor(10., requires_grad=True)\n",
      "w: tensor(3., requires_grad=True)\n",
      "b tensor(5., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"w:\", w)\n",
    "print(\"b\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "87241e84-e883-490b-89b3-2d1ca432df75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(24., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a function y_hat for the tensors\n",
    "y_hat =x**3+w*(x**2)+2*x # Output / Predictions\n",
    "\n",
    "print(\"y_hat:\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "15d774ce-bb59-4363-bb81-5a88ece578dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(196., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f6c4cb95-5602-4f51-aa55-0cca8fd89428",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9431f950-9094-4d28-88cd-65e8e704e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : tensor(728.)\n",
      "w.grad : tensor(112.)\n",
      "b.grad =  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)\n",
    "print(\"b.grad = \",db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec3b7fc-f451-4957-85c6-ce6ec7de1d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5158d58-aa82-4855-aa60-9bfdabf47442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
